{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kr4hm3dMMVXp"
   },
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FU_jE-Lde272",
    "outputId": "ebf52645-02c0-47f8-cce2-e3ff93772f49",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "!pip install keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xx1PI152sDsx",
    "outputId": "e4d19b67-fdc8-40b8-cb46-b741a30eab35",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# unzip dataset from drive\n",
    "!unzip \"/content/drive/MyDrive/data/xmy2vts_reduced_train.zip\" -d \"/content/xmy2vts_reduced_train\"\n",
    "!unzip \"/content/drive/MyDrive/data/xmy2vts_reduced_test.zip\" -d \"/content/xmy2vts_reduced_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZDX4SYqMaxx"
   },
   "source": [
    "### Dataset loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIamUPsji5zR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import normalize, to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_path = \"/content/xmy2vts_reduced_train\"\n",
    "test_path = \"/content/xmy2vts_reduced_test\"\n",
    "\n",
    "\n",
    "# carica la sequenza di frame associata ad un particolare video\n",
    "def load_sequence(video_path):\n",
    "  seq = []\n",
    "  frames = os.listdir(video_path)\n",
    "  frames.sort()\n",
    "  for frame in frames:\n",
    "    frame_path = video_path + '/' + frame\n",
    "    img = cv2.imread(frame_path, 1)\n",
    "    seq.append(img)\n",
    "  return seq\n",
    "\n",
    "\n",
    "# carica tutte le sequenze di frame nella directory specificata\n",
    "def load_videos(groupX, groupY, dir_path):\n",
    "  videos = os.listdir(dir_path)\n",
    "  videos.sort()\n",
    "  for video in videos:\n",
    "\n",
    "    # carica la sequenza di frames dal file\n",
    "    video_path = dir_path + '/' + video\n",
    "    seq = load_sequence(video_path)\n",
    "    groupX.append(seq)\n",
    "\n",
    "    # determina la label ed inseriscila in trainY\n",
    "    label = dir_path[-5:-2]\n",
    "    groupY.append(label)\n",
    "\n",
    "\n",
    "# carica un gruppo di dati (train set, test set)\n",
    "def load_group(group_path):\n",
    "  groupX = list()\n",
    "  groupY = list()\n",
    "\n",
    "  dirs = os.listdir(group_path)\n",
    "  dirs.sort()\n",
    "  for dir in dirs:\n",
    "    dir_path = group_path + '/' + dir\n",
    "    load_videos(groupX, groupY, dir_path)\n",
    "  groupX = np.array(groupX)\n",
    "  groupY = np.array(groupY)\n",
    "  return groupX, groupY\n",
    "\n",
    "\n",
    "# carica l'intero dataset\n",
    "def load_dataset():\n",
    "  trainX = list()\n",
    "  trainY = list()\n",
    "  testX = list()\n",
    "  testY = list()\n",
    "\n",
    "  # carico il dataset dalle directories\n",
    "  trainX, trainY = load_group(train_path)\n",
    "  testX, testY = load_group(test_path)\n",
    "\n",
    "  # pre-processing sulle labels\n",
    "  label_encoder = LabelEncoder()\n",
    "  trainY = label_encoder.fit_transform(trainY)\n",
    "  testY = label_encoder.fit_transform(testY)\n",
    "\n",
    "  trainY = to_categorical(trainY)\n",
    "  testY = to_categorical(testY)\n",
    "\n",
    "  return trainX, trainY, testX, testY\n",
    "\n",
    "\n",
    "def load_dataset_npz(train_path, test_path):\n",
    "\n",
    "  # carico il dataset dalle directories\n",
    "  trainData = np.load(train_path)\n",
    "  trainX = trainData['trainX']\n",
    "  trainY = trainData['trainY']\n",
    "  del trainData\n",
    "\n",
    "  testData = np.load(test_path)\n",
    "  testX = testData['testX']\n",
    "  testY = testData['testY']\n",
    "  del testData\n",
    "\n",
    "  return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD22w6dBdJSQ"
   },
   "source": [
    "### Model 1\n",
    "VGG16 w/ Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1pYAVK4dOvv"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Input, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras import applications\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "# hyperparams\n",
    "n_unit = 512\n",
    "batch_size = 4\n",
    "learning_rate = 0.0001\n",
    "epochs = 375\n",
    "epochs_load = 0\n",
    "epochs_save = epochs_load+epochs\n",
    "\n",
    "\n",
    "def get_cnn_lstm(tuning=False):\n",
    "  cnn_model = VGG16(weights='imagenet', include_top=False, input_shape=(200,200,3))\n",
    "  model_input = Input(shape=(50, 200, 200, 3), name='seq_input')\n",
    "\n",
    "  x = TimeDistributed(cnn_model)(model_input)\n",
    "  x = TimeDistributed(Flatten())(x)\n",
    "  x = LSTM(n_unit)(x)\n",
    "  out = Dense(46, activation='softmax')(x)\n",
    "  \n",
    "  model = Model(inputs=[model_input], outputs=out)\n",
    "  model.summary()\n",
    "\n",
    "  if tuning and epochs_load:\n",
    "    print('Loading epochs '+str(epochs_load)+' weights...')\n",
    "    model.load_weights('/content/epochs'+str(epochs_load)+'.h5')\n",
    "    print(\"...loaded!\")\n",
    "  \n",
    "  #freeze previous layers\n",
    "  for layer in cnn_model.layers:\n",
    "    layer.trainable = False\t\n",
    "  \n",
    "  optimizer = Adam(learning_rate=learning_rate)\n",
    "  loss = 'categorical_crossentropy'\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "def train_test_model(trainX, trainY, testX, testY, tuning=False):\n",
    "  model = get_cnn_lstm(tuning=tuning)\n",
    "\n",
    "  model.fit(trainX, trainY,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1)\n",
    "  \n",
    "  if tuning:\n",
    "    model.save_weights('/content/epochs'+str(epochs_save)+'.h5')\n",
    "\n",
    "  _, accuracy = model.evaluate(testX, testY, batch_size=1)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STVwjYEmLGXX"
   },
   "source": [
    "### Model 2\n",
    "VGG16 w/ VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4M88bNlxcnZj"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Input, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras import applications\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "# hyperparams\n",
    "n_unit = 512\n",
    "batch_size = 4\n",
    "learning_rate = 0.0001\n",
    "epochs = 325\n",
    "epochs_load = 0\n",
    "epochs_save = epochs_load+epochs\n",
    "\n",
    "\n",
    "def get_cnn_lstm(tuning=False):\n",
    "  cnn_model = VGGFace(include_top=False, input_shape=(200,200,3))\n",
    "  model_input = Input(shape=(50, 200, 200, 3), name='seq_input')\n",
    "\n",
    "  x = TimeDistributed(cnn_model)(model_input)\n",
    "  x = TimeDistributed(Flatten())(x)\n",
    "  x = LSTM(n_unit)(x)\n",
    "  out = Dense(46, activation='softmax')(x)\n",
    "  \n",
    "  model = Model(inputs=[model_input], outputs=out)\n",
    "  model.summary()\n",
    "\n",
    "  if tuning and epochs_load:\n",
    "    print('Loading epochs '+str(epochs_load)+' weights...')\n",
    "    model.load_weights('/content/epochs'+str(epochs_load)+'.h5')\n",
    "    print(\"...loaded!\")\n",
    "  \n",
    "  # freeze previous layers\n",
    "  for layer in cnn_model.layers:\n",
    "    layer.trainable = False\t\n",
    "  \n",
    "  optimizer = Adam(learning_rate=learning_rate)\n",
    "  loss = 'categorical_crossentropy'\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "def train_test_model(trainX, trainY, testX, testY, \n",
    "                     tuning=False, save=False):\n",
    "  model = get_cnn_lstm(tuning=tuning)\n",
    "\n",
    "  model.fit(trainX, trainY,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1)\n",
    "  \n",
    "  if tuning:\n",
    "    model.save_weights('/content/epochs'+str(epochs_save)+'.h5')\n",
    "  \n",
    "  if save:\n",
    "    print('Saving model...')\n",
    "    model.save('/content/type3_model')\n",
    "    print('Saving datas...')\n",
    "    np.savez('/content/type3_datas', trainX=trainX, trainY=trainY,\n",
    "             testX=testX, testY=testY)\n",
    "\n",
    "  _, accuracy = model.evaluate(testX, testY, batch_size=1)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVu7vkUGKlv9"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gw59ZVJSjGd",
    "outputId": "cf41ee69-74d9-4339-80dd-6519d64facc9"
   },
   "outputs": [],
   "source": [
    "# carica in train i dati senza mascherina\n",
    "# in test i dati con mascherina\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVyJ0rc3-jm-",
    "outputId": "d69dcd70-1278-44e9-bbef-505207765237"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# carica in X tutti i dati, sia con mascherina che senza\n",
    "# in Y tutte le etichette\n",
    "X = np.concatenate((trainX, testX))\n",
    "Y = np.concatenate((trainY, testY))\n",
    "\n",
    "# elimino i vecchi dati per liberare spazio\n",
    "del trainX\n",
    "del trainY\n",
    "del testX\n",
    "del testY\n",
    "\n",
    "#sceglie casualmente le sequenze e le divide in train e test\n",
    "trainX, testX, trainY, testY = train_test_split(\n",
    "    X, Y, test_size=0.30, random_state=42, stratify=Y)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AVMzLbb3mw3"
   },
   "source": [
    "**Per caricare il dataset da array numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWvhBnerQMnI"
   },
   "outputs": [],
   "source": [
    "# carico xm2vts dagli array numpy perché pesa troppo\n",
    "trainX, trainY, testX, testY = load_dataset_npz(\n",
    "    'drive/MyDrive/data/xmy2vts_train70.npz',\n",
    "    'drive/MyDrive/data/xmy2vts_test30.npz')\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-p6HQLz_okC"
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "del trainX\n",
    "del trainY\n",
    "del testX\n",
    "del testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziS0Z9DgK1XI"
   },
   "source": [
    "### Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0g2m-uME-vV5"
   },
   "outputs": [],
   "source": [
    "# Eseguo il tuning dei parametri del modello \n",
    "# per determinare i migliori iperparametri\n",
    "accuracy = train_test_model(trainX, trainY, testX, testY, tuning=True)\n",
    "accuracy = accuracy * 100.0\n",
    "print('> %.3f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3Xm3wpX1M08"
   },
   "source": [
    "### Experiments\n",
    "Esecuzione degli esperimenti di tipo I, II e III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccpCssY01FMR",
    "outputId": "636874b1-872a-4b59-8794-6093f4bee86a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tipo I e Tipo III\n",
    "accuracy = train_test_model(trainX, trainY, testX, testY, tuning=False, save=True)\n",
    "accuracy = accuracy * 100.0\n",
    "print('> %.3f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CNBb_zhAW-E"
   },
   "outputs": [],
   "source": [
    "# Tipo II\n",
    "accuracy = train_test_model(testX, testY, trainX, trainY, tuning=False, save=True)\n",
    "accuracy = accuracy * 100.0\n",
    "print('> %.3f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR4G7zGvPorm"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYsPx1F61ly8"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/content/drive/MyDrive')\n",
    "\n",
    "# function to turn onehot encoded label into integer\n",
    "def multi_onehot_to_int(y):\n",
    "  output = []\n",
    "  for sample in range(np.shape(y)[0]):\n",
    "\n",
    "    pred_class = []\n",
    "    for c in range(len(y[sample])):\n",
    "      if (y[sample][c] == 1):\n",
    "        output.append(c)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uH0yJnL-Py5c"
   },
   "outputs": [],
   "source": [
    "from plotGraph import plotGraf\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "path = 'drive/MyDrive/xm2vts_reduced_exp'\n",
    "exp_type = 'type3'\n",
    "model_path = path+'/'+exp_type+'_model'\n",
    "data_path = path+'/'+exp_type+'_datas.npz'\n",
    "\n",
    "\n",
    "# load model and datas\n",
    "model = keras.models.load_model(model_path)\n",
    "data = np.load(data_path)\n",
    "testX = data['testX']\n",
    "testY = data['testY']\n",
    "testY = multi_onehot_to_int(testY)\n",
    "testY = np.array(testY)\n",
    "n_output = max(testY) + 1\n",
    "\n",
    "# predict labels\n",
    "scoreY = model.predict(testX, batch_size=1)\n",
    "predY = np.argmax(scoreY, axis=1)\n",
    "\n",
    "# metrics\n",
    "report = metrics.classification_report(testY, predY)\n",
    "print(\"Report \\n%s\" % (report))\n",
    "\n",
    "# confusion matrix\n",
    "matrix = metrics.confusion_matrix(testY, predY)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(17, 17)\n",
    "\n",
    "plt.imshow(matrix)\n",
    "plt.colorbar()\n",
    "ticks = np.linspace(0, n_output-1, num=n_output)\n",
    "plt.xticks(ticks, fontsize=10)\n",
    "plt.yticks(ticks, fontsize=10)\n",
    "\n",
    "# for i in range(n_output):\n",
    "#   for j in range(n_output):\n",
    "#     c = matrix[j,i]\n",
    "#     if c > int(len(testY) / (2 * n_output)):\n",
    "#       color='black'\n",
    "#     else:\n",
    "#       color='white'\n",
    "#     plt.text(i, j, str(c), va='center', ha='center', color=color)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plot ROC and CMC curves\n",
    "plotGraf = plotGraf()\n",
    "plotGraf.plot(testY, predY, scoreY, exp_type, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBAecuJK1Cpw"
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "del data\n",
    "del testX\n",
    "del testY"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Kr4hm3dMMVXp",
    "dZDX4SYqMaxx",
    "WD22w6dBdJSQ",
    "STVwjYEmLGXX",
    "LVu7vkUGKlv9",
    "ziS0Z9DgK1XI",
    "Q3Xm3wpX1M08"
   ],
   "machine_shape": "hm",
   "name": "progetto.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
