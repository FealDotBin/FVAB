{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhBbRAzg1mf5"
   },
   "source": [
    "## Mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ol4xZ0r-1bB3",
    "outputId": "e63da09c-1bef-4ccf-bda4-f1bb8cf3a972"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwcGwHcvIhna"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUHw4vbk12it"
   },
   "source": [
    "Si esegue l'unzip del dataset presente su drive, usando '/content/partX' come destinazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACz5pd3s1KGS"
   },
   "outputs": [],
   "source": [
    "!unzip \"drive/MyDrive/part4.zip\" -d \"/content/part4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn5r1ci52qwi"
   },
   "source": [
    "Si crea tutta la struttura di directory di destinazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bV_EwOW_1fFr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# src_path è il path del dataset\n",
    "# dst_path è il path in cui salveremo il dataset processato\n",
    "src_path = '/content/part4'\n",
    "dst_path = '/content/part4_proc'\n",
    "n_dir = 69\n",
    "\n",
    "def make_dirs():\n",
    "  directories = os.listdir(src_path)\n",
    "\n",
    "  for directory in directories:\n",
    "    os.mkdir(dst_path+'/'+directory+'_0')\n",
    "    os.mkdir(dst_path+'/'+directory+'_1')\n",
    "    \n",
    "    src_dir_path = src_path+'/'+directory\n",
    "    files = os.listdir(src_dir_path)\n",
    "    for file in files:\n",
    "\n",
    "      if '.avi' in file:\n",
    "        dst_dir_path = dst_path+'/'+directory+'_0'\n",
    "        file_no_ext = file[:-4]\n",
    "        os.mkdir(dst_dir_path+'/'+file_no_ext)\n",
    "\n",
    "      else:\n",
    "        dst_dir_path = dst_path+'/'+directory+'_1'\n",
    "        os.mkdir(dst_dir_path+'/'+file)\n",
    "\n",
    "\n",
    "def check():\n",
    "  directories = os.listdir(dst_path)\n",
    "\n",
    "  if len(directories) is not n_dir*2:\n",
    "    print(\"missing directories\")\n",
    "  \n",
    "  for directory in directories:\n",
    "    files = os.listdir(dst_path+'/'+directory)\n",
    "    \n",
    "    if len(files) is not 5:\n",
    "      print(\"missing files\")\n",
    "\n",
    "\n",
    "make_dirs()\n",
    "check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvBl0-Sz26jl"
   },
   "source": [
    "Si processa il dataset eseguendo la detection del volto ed il cropping della regione perioculare.<br>\n",
    "Le sequenze di frame senza mascherina vengono salvate nelle directory xxx_0.<br>\n",
    "Le sequenze di frame con mascherina vengono salvate nelle directory xxx_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWjPhmM_1iw2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "\n",
    "# src_path è il path del dataset\n",
    "# dst_path è il path in cui salveremo il dataset processato\n",
    "src_path = '/content/part4'\n",
    "dst_path = '/content/part4_proc'\n",
    "\n",
    "# detector e predictor per eseguire la detection del volto\n",
    "# e stabilire i landmark facciali\n",
    "detector_dat = 'drive/MyDrive/mmod_human_face_detector.dat'\n",
    "predictor_dat = 'drive/MyDrive/shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.cnn_face_detection_model_v1(detector_dat)\n",
    "predictor = dlib.shape_predictor(predictor_dat)\n",
    "\n",
    "# width ed height sono lunghezza ed altezza dei frame\n",
    "# dopo essere stati processati\n",
    "width = 200\n",
    "height = 200\n",
    "\n",
    "\n",
    "# per trovare il riferimento (landmark) più in alto\n",
    "def find_highest_ref(landmarks):\n",
    "    references = []\n",
    "    references.append(landmarks.part(17).y)\n",
    "    references.append(landmarks.part(18).y)\n",
    "    references.append(landmarks.part(19).y)\n",
    "    references.append(landmarks.part(20).y)\n",
    "    references.append(landmarks.part(21).y)\n",
    "    references.append(landmarks.part(22).y)\n",
    "    references.append(landmarks.part(23).y)\n",
    "    references.append(landmarks.part(24).y)\n",
    "    references.append(landmarks.part(25).y)\n",
    "    references.append(landmarks.part(26).y)\n",
    "    return min(references)\n",
    "\n",
    "\n",
    "# per trovare il riferimento (landmark) più in basso\n",
    "def find_lowest_ref(landmarks):\n",
    "    references = []\n",
    "    references.append(landmarks.part(28).y)\n",
    "    references.append(landmarks.part(36).y)\n",
    "    references.append(landmarks.part(41).y)\n",
    "    references.append(landmarks.part(40).y)\n",
    "    references.append(landmarks.part(39).y)\n",
    "    references.append(landmarks.part(42).y)\n",
    "    references.append(landmarks.part(47).y)\n",
    "    references.append(landmarks.part(46).y)\n",
    "    references.append(landmarks.part(45).y)\n",
    "    return max(references)\n",
    "\n",
    "\n",
    "# prende in input un frame e dà in output un frame \n",
    "# della regione perioculare con size widthxheight \n",
    "def crop_frame(frame):\n",
    "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  faces = detector(gray, 1)\n",
    "\n",
    "  # se non sono stati trovati volti, restituisci None\n",
    "  if not faces:\n",
    "    return None\n",
    "\n",
    "  # trova i landmark ed esegui il cropping\n",
    "  for face in faces:\n",
    "    landmarks = predictor(gray, face.rect)\n",
    "\n",
    "    # fisso i riferimenti da usare\n",
    "    left = landmarks.part(0).x\n",
    "    top = find_highest_ref(landmarks) - 15\n",
    "    right = landmarks.part(16).x\n",
    "    bottom = find_lowest_ref(landmarks) + 15\n",
    "\n",
    "    # taglio la ROI della pericoulare e la riadatto con shape widthxheigh\n",
    "    frame = frame[top:bottom, left:right]\n",
    "\n",
    "    # se il frame non è vuoto, faccio la resize\n",
    "    if frame.size:\n",
    "      frame = cv2.resize(frame, (width, height))\n",
    "      return frame\n",
    "\n",
    "    # altrimenti resituisco None\n",
    "    else:\n",
    "      return None\n",
    "\n",
    "\n",
    "# esegue il cropping della regione perioculare\n",
    "# sui primi 50 frame di un video\n",
    "def manage_video(src_dir_path, dst_dir_path, file):\n",
    "  file_no_ext = file[:-4]\n",
    "  cap = cv2.VideoCapture(src_dir_path+'/'+file)\n",
    "  counter = 0\n",
    "\n",
    "  while counter < 50 and cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "      frame = crop_frame(frame)\n",
    "\n",
    "      # salvo il frame croppato\n",
    "      if frame is not None:\n",
    "        dst_file_path = dst_dir_path+'/'+file_no_ext\n",
    "        framename = file_no_ext+'_'+str(counter).zfill(2)+'.jpeg'\n",
    "        cv2.imwrite(dst_file_path+'/'+framename, frame)\n",
    "        counter += 1\n",
    "    else:\n",
    "      break\n",
    "\n",
    "  # cleanup\n",
    "  cap.release()\n",
    "\n",
    "\n",
    "def manage_file(src_dir_path, dst_dir_path, file):\n",
    "  src_file_path = src_dir_path+'/'+file\n",
    "  dst_file_path = dst_dir_path+'/'+file\n",
    "  framenames = os.listdir(src_file_path)\n",
    "\n",
    "  for framename in framenames:\n",
    "    frame = cv2.imread(src_file_path+'/'+framename, 1)\n",
    "    frame = crop_frame(frame)\n",
    "\n",
    "    # salvo il frame croppato\n",
    "    if frame is not None:\n",
    "      cv2.imwrite(dst_file_path+'/'+framename, frame)\n",
    "\n",
    "\n",
    "def main():\n",
    "  directories = os.listdir(src_path)\n",
    "\n",
    "  for directory in directories:\n",
    "    src_dir_path = src_path+'/'+directory\n",
    "    files = os.listdir(src_dir_path)\n",
    "\n",
    "    for file in files:\n",
    "      print(\"computing file %s/%s\" % (src_dir_path, file))\n",
    "\n",
    "      if '.avi' in file:\n",
    "        dst_dir_path = dst_path+'/'+directory+'_0'\n",
    "        manage_video(src_dir_path, dst_dir_path, file)\n",
    "\n",
    "      else:\n",
    "        dst_dir_path = dst_path+'/'+directory+'_1'\n",
    "        manage_file(src_dir_path, dst_dir_path, file)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqlcKo8G3Nwk"
   },
   "source": [
    "Si zippa il dataset processato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVYN8cwe1k1k"
   },
   "outputs": [],
   "source": [
    "!zip -r part4_proc.zip part4_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI1uW_PrIoem"
   },
   "source": [
    "## Preprocessing video non conformi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wy0lP6DbIrv5",
    "outputId": "6c5b375e-8dfe-496f-ecc7-a0fdbc6aa5ab",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip \"drive/MyDrive/XM2VTS.zip\" -d \"XM2VTS\"\n",
    "!unzip \"drive/MyDrive/XMY2VTS.zip\" -d \"XMY2VTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOVqRUuJJDu3",
    "outputId": "914b5096-3df0-4c22-ee1d-4bdb3842c7d7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "\n",
    "# src_path è il path del dataset\n",
    "# dst_path è il path in cui salveremo il dataset processato\n",
    "src_path = '/content/XM2VTS/XM2VTS'\n",
    "dst_path = '/content/XMY2VTS/XMY2VTS'\n",
    "\n",
    "# detector e predictor per eseguire la detection del volto\n",
    "# e stabilire i landmark facciali\n",
    "detector_dat = 'drive/MyDrive/mmod_human_face_detector.dat'\n",
    "predictor_dat = 'drive/MyDrive/shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.cnn_face_detection_model_v1(detector_dat)\n",
    "predictor = dlib.shape_predictor(predictor_dat)\n",
    "\n",
    "# width ed height sono lunghezza ed altezza dei frame\n",
    "# dopo essere stati processati\n",
    "width = 200\n",
    "height = 200\n",
    "\n",
    "\n",
    "# per trovare il riferimento (landmark) più in alto\n",
    "def find_highest_ref(landmarks):\n",
    "    references = []\n",
    "    references.append(landmarks.part(17).y)\n",
    "    references.append(landmarks.part(18).y)\n",
    "    references.append(landmarks.part(19).y)\n",
    "    references.append(landmarks.part(20).y)\n",
    "    references.append(landmarks.part(21).y)\n",
    "    references.append(landmarks.part(22).y)\n",
    "    references.append(landmarks.part(23).y)\n",
    "    references.append(landmarks.part(24).y)\n",
    "    references.append(landmarks.part(25).y)\n",
    "    references.append(landmarks.part(26).y)\n",
    "    return min(references)\n",
    "\n",
    "\n",
    "# per trovare il riferimento (landmark) più in basso\n",
    "def find_lowest_ref(landmarks):\n",
    "    references = []\n",
    "    references.append(landmarks.part(28).y)\n",
    "    references.append(landmarks.part(36).y)\n",
    "    references.append(landmarks.part(41).y)\n",
    "    references.append(landmarks.part(40).y)\n",
    "    references.append(landmarks.part(39).y)\n",
    "    references.append(landmarks.part(42).y)\n",
    "    references.append(landmarks.part(47).y)\n",
    "    references.append(landmarks.part(46).y)\n",
    "    references.append(landmarks.part(45).y)\n",
    "    return max(references)\n",
    "\n",
    "\n",
    "# esegue il cropping della regione perioculare\n",
    "# sui primi 50 frame di un video\n",
    "def manage_video(src_dir_path, dst_dir_path, file):\n",
    "  file_no_ext = file[:-4]\n",
    "  cap = cv2.VideoCapture(src_dir_path+'/'+file)\n",
    "  counter = 0\n",
    "\n",
    "  while counter < 50 and cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "      faces = detector(gray, 1)\n",
    "\n",
    "      # trova i landmark ed esegui il cropping\n",
    "      for face in faces:\n",
    "        landmarks = predictor(gray, face.rect)\n",
    "\n",
    "        # fisso i riferimenti da usare\n",
    "        left = landmarks.part(0).x\n",
    "        top = find_highest_ref(landmarks) - 15\n",
    "        right = landmarks.part(16).x\n",
    "        bottom = find_lowest_ref(landmarks) + 15\n",
    "\n",
    "        # taglio la ROI della pericoulare e la riadatto con shape widthxheigh\n",
    "        # sul frame con mascherina\n",
    "        dst_file_path = dst_dir_path+'/'+file_no_ext\n",
    "        framename = file_no_ext+'_'+str(counter).zfill(2)+'.jpeg'\n",
    "        frame = cv2.imread(dst_file_path+'/'+framename, 1)\n",
    "        frame = frame[top:bottom, left:right]\n",
    "\n",
    "        # se il frame non è vuoto, faccio la resize e lo salvo\n",
    "        if frame.size:\n",
    "          frame = cv2.resize(frame, (width, height))\n",
    "          cv2.imwrite(dst_file_path+'/'+framename, frame)\n",
    "          counter += 1\n",
    "\n",
    "  # cleanup\n",
    "  cap.release()\n",
    "\n",
    "\n",
    "def main():\n",
    "  directories = os.listdir(src_path)\n",
    "\n",
    "  for directory in directories:\n",
    "    src_dir_path = src_path+'/'+directory\n",
    "    dst_dir_path = dst_path+'/'+directory+'_1'\n",
    "    files = os.listdir(src_dir_path)\n",
    "\n",
    "    for file in files:\n",
    "      print(\"computing file %s/%s\" % (src_dir_path, file))\n",
    "      manage_video(src_dir_path, dst_dir_path, file)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqEAYWlBaU1o",
    "outputId": "72e52b1e-bff9-461e-bd38-44c6bd513d00",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!zip -r XMY2VTS_proc.zip XMY2VTS"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "PhBbRAzg1mf5",
    "iwcGwHcvIhna",
    "kI1uW_PrIoem"
   ],
   "name": "XM2VTS_Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
